{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gpu avaliable:\t1\n",
      "Current GPU:\t0\n",
      "GPU name: \tGeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as dsets\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "num_epoch=20\n",
    "batch_size=32\n",
    "device='cuda'\n",
    "data_root='./data'\n",
    "\n",
    "import allocateGPU\n",
    "allocateGPU.allocate_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks=['no_attacks','omniscient','label_flipping','omniscient_aggresive']\n",
    "attacker_list_labelflipping={'no_attacks':[],'omniscient':[],'label_flipping':[0],'omniscient_aggresive':[]}\n",
    "attacker_list_omniscient={'no_attacks':[],'omniscient':[0],'label_flipping':[],'omniscient_aggresive':[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agg_dataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "        denote n be the number of clients,\n",
    "        each entry of dataset is a 2-tuple of (weight delta, labels):= (1 x n tensor, 1 x n tensor)\n",
    "        honest clients are labeled 1, malicious clients are labeled 0\n",
    "    '''\n",
    "    def __init__(self,path,attacks):\n",
    "        super(Agg_dataset).__init__() \n",
    "        data=torch.load(path,map_location='cpu')\n",
    "        data_tensors=torch.cat([data[param] for param in data],0)\n",
    "        self.data=data_tensors\n",
    "        self.label=attacks\n",
    "        label=attacks/torch.sum(attacks)\n",
    "        self.center=torch.sum(data_tensors*label,1).view(-1,1)\n",
    "        self.num_clients=attacks.shape[0]\n",
    "        self.n=10000\n",
    "        dimension=100\n",
    "        self.indexes=torch.randint(self.data.shape[0],(self.n,100))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "#         \n",
    "\n",
    "        data_out=self.data[self.indexes[index]]\n",
    "        label_out=self.label\n",
    "        center_out=self.center[self.indexes[index]]\n",
    "        perm=torch.randperm(self.num_clients)\n",
    "#         data_sorted=torch.sort(data_out)\n",
    "#         perm=data_sorted[1]\n",
    "        data_out_shuffled=torch.index_select(data_out, -1, perm)\n",
    "\n",
    "        return data_out_shuffled, [label_out[perm],center_out]\n",
    "#         return data_out,[label_out,center_out]\n",
    "    def __len__(self):\n",
    "#         return self.data.shape[0]//100\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(attack):\n",
    "    label=torch.ones(10)\n",
    "    for i in attacker_list_labelflipping[attack]:\n",
    "        label[i]=0\n",
    "    for i in attacker_list_omniscient[attack]:\n",
    "        label[i]=0\n",
    "    path=f'./AggData/{attack}/FedAvg_0.pt'\n",
    "    dataset=Agg_dataset(path,label)\n",
    "    validation_split = .2\n",
    "    shuffle_dataset = True\n",
    "    random_seed= 42\n",
    "\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_loader,criterion,optimizer,device, on):\n",
    "    net.to(device)\n",
    "    for idx, (data,target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target[on].to(device)\n",
    "        optimizer.zero_grad()   \n",
    "        output = net(data)\n",
    "        loss = criterion(output[on], target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "def test(net,test_loader,device,message_prefix):\n",
    "    net.to(device)\n",
    "    accuracy = 0\n",
    "    accuracy_mean = 0\n",
    "    accuracy_median = 0\n",
    "    count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target[1].to(device)\n",
    "            outputs = net(data)\n",
    "            accuracy+=F.l1_loss(outputs[1], target)\n",
    "            accuracy_mean+=F.l1_loss(data.mean(-1).unsqueeze(-1), target)\n",
    "            accuracy_median+=F.l1_loss(data.median(-1)[0].unsqueeze(-1), target)\n",
    "            count+=len(data)\n",
    "    print('Accuracy: %.4E (%.4E, %.4E)' % (accuracy/count,accuracy_mean/count,accuracy_median/count ))\n",
    "    return accuracy/count, accuracy_mean/count, accuracy_median/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mean(batch[0],-1).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "def dot_product(A,B):\n",
    "    return torch.bmm(A.view(A.shape[0],1,A.shape[1]),B.view(B.shape[0],B.shape[1],1))\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self,in_dim, n ,m ):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.in_dim=in_dim\n",
    "        self.n = n\n",
    "        self.fc1 = nn.Linear(self.in_dim*n, m)\n",
    "        self.fc2 = nn.Linear(m, m)\n",
    "        self.fc3 = nn.Linear(m, self.n)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, self.in_dim*self.n)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        pred = torch.sum(x.view(-1,1,self.n)*input,dim=-1).unsqueeze(-1)/9\n",
    "    \n",
    "        return x,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,n,in_dim):\n",
    "        super(CNN, self).__init__()\n",
    "        self.in_dim=in_dim\n",
    "        self.fc1 = nn.Conv1d(1, n, kernel_size=3,dilation=1, padding=1)\n",
    "        self.fc2 = nn.Conv1d(n, n, kernel_size=3,dilation=2, padding=2)\n",
    "        self.fc3 = nn.Conv1d(n, self.in_dim, kernel_size=3,dilation=1, padding=1)\n",
    "        self.maxpool1=nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(-1, 1, self.in_dim)\n",
    "        x = nn.LeakyReLU()(self.fc1(x))\n",
    "        x = nn.LeakyReLU()(self.fc2(x))\n",
    "        x = nn.LeakyReLU()(self.fc3(x))\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x=x.squeeze()\n",
    "        x = F.softmax(x,dim=1)\n",
    "        pred=dot_product(x,input).squeeze(-1)\n",
    "        return x, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self,in_,out_):\n",
    "        super(block, self).__init__()\n",
    "        self.main=torch.nn.Sequential(\n",
    "                    nn.Conv2d(in_, out_, kernel_size=1),\n",
    "                    torch.nn.BatchNorm2d(out_),\n",
    "                    nn.ReLU(),\n",
    "                    )\n",
    "    def forward(self,x):\n",
    "        out=self.main(x)\n",
    "        return out\n",
    "    \n",
    "class block_no_activation(nn.Module):\n",
    "    def __init__(self,in_,out_):\n",
    "        super(block_no_activation, self).__init__()\n",
    "        self.main=torch.nn.Sequential(\n",
    "                    nn.Conv2d(in_, out_, kernel_size=1),\n",
    "                    torch.nn.BatchNorm2d(out_),\n",
    "                    )\n",
    "    def forward(self,x):\n",
    "        out=self.main(x)\n",
    "        return out\n",
    "    \n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self,in_dim, n):\n",
    "        '''\n",
    "        in_dim:=dimension of weight vector\n",
    "        n:= number of clients\n",
    "        '''\n",
    "        super(PointNet, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.n = n\n",
    "        self.local = torch.nn.Sequential(\n",
    "                        block(self.in_dim,64),\n",
    "                        block(64,64),\n",
    "                        block(64,64)\n",
    "                    )\n",
    "        self.globa = torch.nn.Sequential(\n",
    "                        block(64,128),\n",
    "                        block(128,1024),\n",
    "                        nn.AdaptiveMaxPool2d(1)\n",
    "                    )\n",
    "        self.direct_out= block(1024,10)\n",
    "        self.MLP = torch.nn.Sequential(\n",
    "                        block(1088,512),\n",
    "                        block(512,256),\n",
    "                        block(256,128),\n",
    "                        nn.Dropout(p=0.7, inplace=True),\n",
    "                        block_no_activation(128,1)\n",
    "                      )\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "#         x = input.view(-1, self.n, self.in_dim)\n",
    "        x=input.view(-1,self.in_dim,self.n,1)\n",
    "        for module in self.local:\n",
    "            x = module(x)\n",
    "#             print(f'local:\\t {x.shape}')\n",
    "        x_local=x\n",
    "        for module in self.globa:\n",
    "            x = module(x)\n",
    "#             print(f'global:\\t {x.shape}')\n",
    "        x_global=x.repeat(1,1,self.n,1)\n",
    "#         print(f'tile:\\t {x_global.shape}')\n",
    "        x=torch.cat([x_local,x_global],dim=1)\n",
    "#         print(x.shape)\n",
    "        for module in self.MLP:\n",
    "            x = module(x)\n",
    "#             print(f'MLP:\\t {x.shape}')\n",
    "#         x=self.direct_out(x)\n",
    "        x=x.squeeze()\n",
    "#        x = F.softmax(x,dim=1)\n",
    "        x = torch.sigmoid(x)\n",
    "#         pred=dot_product(input,x).squeeze(-1)\n",
    "#        x2= F.softmax(x,dim=1)\n",
    "        x3 = (x>0.5).float().cuda()\n",
    "        x3 = x3/torch.sum(x3,-1).view(-1,1)\n",
    "        pred = torch.sum(x3.view(-1,1,self.n)*input,dim=-1).unsqueeze(-1)\n",
    "\n",
    "        return x,pred\n",
    "\n",
    "    def forward2(self, input, n):\n",
    "#         x = input.view(-1, self.n, self.in_dim)\n",
    "        x=input.view(-1,self.in_dim,n,1)\n",
    "        for module in self.local:\n",
    "            x = module(x)\n",
    "#             print(f'local:\\t {x.shape}')\n",
    "        x_local=x\n",
    "        for module in self.globa:\n",
    "            x = module(x)\n",
    "#             print(f'global:\\t {x.shape}')\n",
    "        x_global=x.repeat(1,1,n,1)\n",
    "#         print(f'tile:\\t {x_global.shape}')\n",
    "        x=torch.cat([x_local,x_global],dim=1)\n",
    "#         print(x.shape)\n",
    "        for module in self.MLP:\n",
    "            x = module(x)\n",
    "#             print(f'MLP:\\t {x.shape}')\n",
    "#         x=self.direct_out(x)\n",
    "        x=x.squeeze()\n",
    "#        x = F.softmax(x,dim=1)\n",
    "        x = torch.sigmoid(x)\n",
    "#         pred=dot_product(input,x).squeeze(-1)\n",
    "#        x2= F.softmax(x,dim=1)\n",
    "        x3 = (x>0.5).float().cuda()\n",
    "        x3 = x3/torch.sum(x3,-1).view(-1,1)\n",
    "        pred = torch.sum(x3.view(-1,1,n)*input,dim=-1).unsqueeze(-1)\n",
    "\n",
    "        return x,pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "def write(name,scalar):\n",
    "    writer=SummaryWriter(f'./agg_logs/{name}')\n",
    "    writer.add_scalar('l1 loss', scalar, 0)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders={attack:get_loader(attack) for attack in attacks}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mean(batch[0][1],1)\n",
    "# 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 100, 1])\n"
     ]
    }
   ],
   "source": [
    "batch=next(iter(loaders[attacks[1]][0]))\n",
    "print(batch[0].shape)\n",
    "print(batch[1][0].shape)\n",
    "print(batch[1][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch=next(iter(loaders[attacks[1]][0]))\n",
    "net_p=PointNet(100,10).cuda()\n",
    "net_p(batch[0].cuda())[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training of omniscient/PointNet/BCELoss/lr_0.1\n",
      "Accuracy: 5.2091E-08 (1.8397E-05, 5.9228E-07)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3763b2ac35d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                     \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_alias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-91f43557f886>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, criterion, optimizer, device, on)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg_fmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg_fmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg_fmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg_fmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mode_name=['classification']\n",
    "for attack in attacks[1:]:\n",
    "    train_loader, test_loader=loaders[attack]\n",
    "    for criterion in [torch.nn.BCELoss()]:\n",
    "        mode=0\n",
    "        for lr in [0.1,0.01,0.001]:\n",
    "\n",
    "            net_ptnet=PointNet(100,10)\n",
    "\n",
    "            for net in [net_ptnet]:\n",
    "                \n",
    "                training_alias=f'{attack}/{net.__class__.__name__}/{criterion.__class__.__name__}/lr_{lr}'\n",
    "                if training_alias in accuracy_list:\n",
    "                    continue\n",
    "                \n",
    "                print('Start training of %s'%training_alias)\n",
    "                optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "                for epoch in range(num_epoch):\n",
    "                    train(net,train_loader,criterion,optimizer,device,mode)\n",
    "                    score=test(net,test_loader,device,'')\n",
    "                write(training_alias,score[0])\n",
    "                accuracy_list[training_alias]=score[0].item()\n",
    "    accuracy_list[f'{attack}/mean']=score[1].item()\n",
    "    write(f'{attack}/mean',score[1])\n",
    "    accuracy_list[f'{attack}/median']=score[2].item()\n",
    "    write(f'{attack}/median',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net=Mlp(100,10,10).cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    criterion=torch.nn.BCELoss()\n",
    "    data=batch[0].cuda()\n",
    "    target=batch[1][0].cuda()\n",
    "    optimizer.zero_grad()   \n",
    "    output = net(data)\n",
    "    loss = criterion(output[0], target)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(output[0][0])\n",
    "print(target[0])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[9.9816e-01, 9.9900e-01, 9.9871e-01, 9.9842e-01, 9.9934e-01, 9.9866e-01,\n",
       "          2.1455e-07, 9.9862e-01, 9.9580e-01, 9.9952e-01],\n",
       "         [9.9891e-01, 9.9839e-01, 9.9895e-01, 9.9945e-01, 9.9878e-01, 9.9860e-01,\n",
       "          9.9788e-01, 9.9873e-01, 1.1962e-08, 9.9872e-01],\n",
       "         [9.9912e-01, 3.8677e-04, 9.9782e-01, 9.9905e-01, 9.9783e-01, 9.9726e-01,\n",
       "          9.9831e-01, 9.9848e-01, 9.9853e-01, 9.9943e-01],\n",
       "         [9.9843e-01, 9.9843e-01, 9.9896e-01, 9.9796e-01, 1.1561e-06, 9.9821e-01,\n",
       "          9.9698e-01, 9.9864e-01, 9.9840e-01, 9.9917e-01],\n",
       "         [9.9920e-01, 9.9841e-01, 9.9891e-01, 9.9847e-01, 9.9805e-01, 9.9908e-01,\n",
       "          9.9895e-01, 9.9904e-01, 5.4425e-06, 9.9925e-01],\n",
       "         [9.9814e-01, 9.8365e-04, 9.9690e-01, 9.9894e-01, 9.9899e-01, 9.9739e-01,\n",
       "          9.9848e-01, 9.9849e-01, 9.9921e-01, 9.9893e-01],\n",
       "         [9.9858e-01, 9.9924e-01, 9.9808e-01, 9.9913e-01, 9.9927e-01, 9.9691e-01,\n",
       "          9.9876e-01, 9.9781e-01, 9.9895e-01, 5.1436e-08],\n",
       "         [9.9853e-01, 9.9891e-01, 9.9921e-01, 6.0486e-09, 9.9896e-01, 9.9897e-01,\n",
       "          9.9842e-01, 9.9843e-01, 9.9667e-01, 9.9816e-01],\n",
       "         [9.9797e-01, 9.9903e-01, 9.9880e-01, 9.9941e-01, 9.9815e-01, 9.9835e-01,\n",
       "          9.9764e-01, 9.9878e-01, 4.9959e-05, 9.9732e-01],\n",
       "         [7.6056e-07, 9.9780e-01, 9.9818e-01, 9.9875e-01, 9.9686e-01, 9.9934e-01,\n",
       "          9.9844e-01, 9.9739e-01, 9.9752e-01, 9.9819e-01],\n",
       "         [9.9897e-01, 9.9894e-01, 9.9906e-01, 1.3768e-06, 9.9898e-01, 9.9874e-01,\n",
       "          9.9878e-01, 9.9782e-01, 9.9861e-01, 9.9763e-01],\n",
       "         [9.9807e-01, 9.9913e-01, 9.9861e-01, 9.9860e-01, 9.9905e-01, 9.9837e-01,\n",
       "          9.9836e-01, 1.0719e-04, 9.9890e-01, 9.9751e-01],\n",
       "         [9.9847e-01, 3.9848e-07, 9.9724e-01, 9.9833e-01, 9.9834e-01, 9.9941e-01,\n",
       "          9.9913e-01, 9.9806e-01, 9.9855e-01, 9.9838e-01],\n",
       "         [1.2532e-04, 9.9811e-01, 9.9898e-01, 9.9711e-01, 9.9789e-01, 9.9848e-01,\n",
       "          9.9817e-01, 9.9540e-01, 9.9913e-01, 9.9852e-01],\n",
       "         [9.9811e-01, 9.9933e-01, 9.9848e-01, 9.9870e-01, 9.9864e-01, 9.9677e-01,\n",
       "          9.9884e-01, 9.9872e-01, 8.6116e-07, 9.9822e-01],\n",
       "         [9.9856e-01, 1.7229e-05, 9.9745e-01, 9.9810e-01, 9.9918e-01, 9.9874e-01,\n",
       "          9.9913e-01, 9.9863e-01, 9.9851e-01, 9.9633e-01],\n",
       "         [5.1308e-03, 9.9808e-01, 9.9897e-01, 9.9870e-01, 9.9836e-01, 9.9832e-01,\n",
       "          9.9930e-01, 9.9778e-01, 9.9914e-01, 9.9771e-01],\n",
       "         [9.9797e-01, 9.9916e-01, 9.9913e-01, 9.9865e-01, 9.9671e-01, 9.9819e-01,\n",
       "          9.9812e-01, 9.9860e-01, 2.9500e-02, 9.9877e-01],\n",
       "         [9.9808e-01, 9.9701e-01, 9.9897e-01, 9.9914e-01, 9.9892e-01, 9.9910e-01,\n",
       "          9.9952e-01, 5.1345e-03, 9.9871e-01, 9.9788e-01],\n",
       "         [9.9870e-01, 9.9770e-01, 9.9761e-01, 1.3591e-04, 9.9884e-01, 9.9882e-01,\n",
       "          9.9845e-01, 9.9915e-01, 9.9950e-01, 9.9949e-01],\n",
       "         [1.6145e-03, 9.9825e-01, 9.9912e-01, 9.9893e-01, 9.9840e-01, 9.9794e-01,\n",
       "          9.9875e-01, 9.9776e-01, 9.9937e-01, 9.9949e-01],\n",
       "         [9.9892e-01, 9.9889e-01, 9.9863e-01, 9.9861e-01, 9.9825e-01, 9.0444e-09,\n",
       "          9.9760e-01, 9.9802e-01, 9.9908e-01, 9.9922e-01],\n",
       "         [9.9899e-01, 9.9821e-01, 9.9874e-01, 9.9869e-01, 9.9874e-01, 9.9892e-01,\n",
       "          9.9901e-01, 9.9912e-01, 5.3855e-06, 9.9815e-01],\n",
       "         [9.9734e-01, 9.9871e-01, 9.9877e-01, 9.9750e-01, 9.9823e-01, 9.9960e-01,\n",
       "          1.7536e-08, 9.9942e-01, 9.9679e-01, 9.9896e-01],\n",
       "         [9.9854e-01, 9.9954e-01, 9.9841e-01, 9.9792e-01, 9.9695e-01, 9.9879e-01,\n",
       "          4.7980e-04, 9.9884e-01, 9.9846e-01, 9.9779e-01],\n",
       "         [9.9877e-01, 9.9702e-01, 9.9896e-01, 9.9819e-01, 9.9911e-01, 9.9941e-01,\n",
       "          9.9888e-01, 2.1474e-05, 9.9930e-01, 9.9661e-01],\n",
       "         [9.9803e-01, 9.9731e-01, 9.9902e-01, 9.9873e-01, 9.9867e-01, 9.9909e-01,\n",
       "          3.0909e-04, 9.9905e-01, 9.9908e-01, 9.9770e-01],\n",
       "         [5.8616e-06, 9.9914e-01, 9.9864e-01, 9.9909e-01, 9.9780e-01, 9.9886e-01,\n",
       "          9.9815e-01, 9.9905e-01, 9.9674e-01, 9.9869e-01],\n",
       "         [9.9790e-01, 9.9916e-01, 9.9819e-01, 9.9872e-01, 9.9868e-01, 9.9939e-01,\n",
       "          9.9829e-01, 9.9815e-01, 4.2884e-06, 9.9774e-01],\n",
       "         [9.9879e-01, 9.9857e-01, 9.9858e-01, 9.9902e-01, 1.6088e-05, 9.9822e-01,\n",
       "          9.9779e-01, 9.9958e-01, 9.9832e-01, 9.9791e-01],\n",
       "         [9.9726e-01, 9.9841e-01, 9.9531e-01, 9.9938e-01, 9.9777e-01, 9.9939e-01,\n",
       "          1.7428e-05, 9.9893e-01, 9.9922e-01, 9.9859e-01],\n",
       "         [9.9844e-01, 9.9879e-01, 9.9847e-01, 9.9857e-01, 9.9820e-01, 9.9927e-01,\n",
       "          1.4776e-04, 9.9830e-01, 9.9825e-01, 9.9932e-01]], device='cuda:0',\n",
       "        grad_fn=<SigmoidBackward>), tensor([[[-2.9227e-04],\n",
       "          [-2.6262e-05],\n",
       "          [ 5.5127e-05],\n",
       "          ...,\n",
       "          [ 1.0013e-03],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]],\n",
       " \n",
       "         [[ 4.0339e-04],\n",
       "          [ 7.1133e-04],\n",
       "          [-1.7169e-04],\n",
       "          ...,\n",
       "          [-3.3895e-04],\n",
       "          [-1.4219e-04],\n",
       "          [ 0.0000e+00]],\n",
       " \n",
       "         [[-8.0226e-04],\n",
       "          [ 3.4006e-05],\n",
       "          [-1.3388e-03],\n",
       "          ...,\n",
       "          [-6.1212e-04],\n",
       "          [-1.9643e-04],\n",
       "          [-3.0547e-04]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-3.6294e-05],\n",
       "          [-8.9562e-07],\n",
       "          [ 2.0585e-03],\n",
       "          ...,\n",
       "          [-1.6285e-05],\n",
       "          [-2.8725e-04],\n",
       "          [-1.3190e-04]],\n",
       " \n",
       "         [[-2.2926e-04],\n",
       "          [-3.4706e-04],\n",
       "          [-2.8312e-05],\n",
       "          ...,\n",
       "          [-4.4267e-04],\n",
       "          [-3.2396e-05],\n",
       "          [-2.8626e-03]],\n",
       " \n",
       "         [[ 1.8937e-07],\n",
       "          [ 7.0877e-04],\n",
       "          [-8.6272e-07],\n",
       "          ...,\n",
       "          [ 3.2253e-04],\n",
       "          [ 4.0165e-04],\n",
       "          [ 0.0000e+00]]], device='cuda:0'))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(batch[0].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[9.9808e-01, 9.9851e-01, 9.9890e-01, 9.9914e-01, 9.9808e-01],\n",
       "         [9.9888e-01, 9.9892e-01, 9.9781e-01, 9.9868e-01, 9.9878e-01],\n",
       "         [9.9784e-01, 2.3904e-07, 9.9895e-01, 9.9811e-01, 9.9809e-01],\n",
       "         [9.9809e-01, 9.9923e-01, 9.9914e-01, 9.9753e-01, 1.0071e-04],\n",
       "         [9.9784e-01, 9.9717e-01, 9.9828e-01, 9.9797e-01, 9.9873e-01],\n",
       "         [9.9903e-01, 2.2263e-09, 9.9897e-01, 9.9911e-01, 9.9909e-01],\n",
       "         [9.9864e-01, 9.9835e-01, 9.9916e-01, 9.9772e-01, 9.9819e-01],\n",
       "         [9.9918e-01, 9.9797e-01, 9.9896e-01, 1.8374e-02, 9.9911e-01],\n",
       "         [9.9777e-01, 9.9955e-01, 9.9229e-01, 9.9905e-01, 9.9629e-01],\n",
       "         [2.4453e-04, 9.9890e-01, 9.9839e-01, 9.9883e-01, 9.9816e-01],\n",
       "         [9.9905e-01, 9.9904e-01, 9.9743e-01, 2.4812e-07, 9.9784e-01],\n",
       "         [9.9886e-01, 9.9891e-01, 9.9808e-01, 9.9775e-01, 9.9906e-01],\n",
       "         [9.9889e-01, 3.3394e-06, 9.9891e-01, 9.9943e-01, 9.9896e-01],\n",
       "         [1.7978e-05, 9.9895e-01, 9.9785e-01, 9.9846e-01, 9.9857e-01],\n",
       "         [9.9792e-01, 9.9710e-01, 9.9770e-01, 9.9777e-01, 9.9736e-01],\n",
       "         [9.9876e-01, 1.0672e-07, 9.9936e-01, 9.9840e-01, 9.9896e-01],\n",
       "         [1.4129e-08, 9.9772e-01, 9.9834e-01, 9.9802e-01, 9.9715e-01],\n",
       "         [9.9765e-01, 9.9846e-01, 9.9803e-01, 9.9708e-01, 9.9830e-01],\n",
       "         [9.9663e-01, 9.9578e-01, 9.9710e-01, 9.9831e-01, 9.9828e-01],\n",
       "         [9.9744e-01, 9.9834e-01, 9.9757e-01, 2.7568e-05, 9.9884e-01],\n",
       "         [3.0651e-05, 9.9923e-01, 9.9909e-01, 9.9855e-01, 9.9867e-01],\n",
       "         [9.9868e-01, 9.9823e-01, 9.9830e-01, 9.9927e-01, 9.9804e-01],\n",
       "         [9.9859e-01, 9.9679e-01, 9.9732e-01, 9.9769e-01, 9.9834e-01],\n",
       "         [9.9842e-01, 9.9890e-01, 9.9921e-01, 9.9743e-01, 9.9896e-01],\n",
       "         [9.9631e-01, 9.9856e-01, 9.9692e-01, 9.9943e-01, 9.9844e-01],\n",
       "         [9.9665e-01, 9.9643e-01, 9.9587e-01, 9.9764e-01, 9.9757e-01],\n",
       "         [9.9779e-01, 9.9884e-01, 9.9874e-01, 9.9893e-01, 9.9846e-01],\n",
       "         [8.4553e-08, 9.9940e-01, 9.9931e-01, 9.9852e-01, 9.9939e-01],\n",
       "         [9.9661e-01, 9.9891e-01, 9.9689e-01, 9.9849e-01, 9.9775e-01],\n",
       "         [9.9755e-01, 9.9841e-01, 9.9836e-01, 9.9847e-01, 2.5850e-05],\n",
       "         [9.9636e-01, 9.9815e-01, 9.9805e-01, 9.9875e-01, 9.9905e-01],\n",
       "         [9.9861e-01, 9.9908e-01, 9.9900e-01, 9.9892e-01, 9.9879e-01]],\n",
       "        device='cuda:0', grad_fn=<SigmoidBackward>), tensor([[[-2.9520e-04],\n",
       "          [-2.8827e-05],\n",
       "          [ 5.5484e-05],\n",
       "          ...,\n",
       "          [ 1.0642e-03],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]],\n",
       " \n",
       "         [[ 4.3938e-04],\n",
       "          [ 6.8949e-04],\n",
       "          [-1.5188e-04],\n",
       "          ...,\n",
       "          [-3.1962e-04],\n",
       "          [-1.1392e-04],\n",
       "          [ 0.0000e+00]],\n",
       " \n",
       "         [[-8.0675e-04],\n",
       "          [ 3.6661e-05],\n",
       "          [-1.3112e-03],\n",
       "          ...,\n",
       "          [-6.0791e-04],\n",
       "          [-1.9370e-04],\n",
       "          [-3.1041e-04]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-3.9862e-05],\n",
       "          [-7.1712e-07],\n",
       "          [ 2.0928e-03],\n",
       "          ...,\n",
       "          [-1.8277e-05],\n",
       "          [-2.9054e-04],\n",
       "          [-1.6669e-04]],\n",
       " \n",
       "         [[-2.2036e-04],\n",
       "          [-3.7024e-04],\n",
       "          [-3.3297e-05],\n",
       "          ...,\n",
       "          [-4.2114e-04],\n",
       "          [-3.6125e-05],\n",
       "          [-2.7855e-03]],\n",
       " \n",
       "         [[ 3.4086e-07],\n",
       "          [ 7.0717e-04],\n",
       "          [-7.1507e-07],\n",
       "          ...,\n",
       "          [ 3.7097e-04],\n",
       "          [ 3.8774e-04],\n",
       "          [ 0.0000e+00]]], device='cuda:0'))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_batch=torch.index_select(batch[0],-1,torch.LongTensor([0,1,2,3,4]))\n",
    "net.forward2(small_batch.cuda(),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct=[key.split('/',1)+[accuracy_list[key]] for key  in accuracy_list.keys()]\n",
    "df=pd.DataFrame(np.array([row[2] for row in struct]).reshape(4,6))\n",
    "\n",
    "\n",
    "index=list(OrderedDict.fromkeys([row[0] for row in struct]))\n",
    "df.index=index\n",
    "\n",
    "columns=list(OrderedDict.fromkeys([row[1] for row in struct]))\n",
    "df.columns=columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the minimum in a Series yellow.\n",
    "    '''\n",
    "    is_min = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_min]\n",
    "\n",
    "print(\"\\nHighlight the minimum value in each column:\")\n",
    "df.T.style.apply(highlight_max,subset=pd.IndexSlice[:, df.T.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distribution of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack=attacks[1]\n",
    "label=torch.ones(10)\n",
    "for i in attacker_list_labelflipping[attack]:\n",
    "    label[i]=0\n",
    "for i in attacker_list_omniscient[attack]:\n",
    "    label[i]=0\n",
    "path=f'./AggData/{attack}/FedAvg_0.pt'\n",
    "dataset=Agg_dataset(path,label)\n",
    "dist=dataset.center.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(np.log(np.abs(dist))).replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quantile([0.25,0.75])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

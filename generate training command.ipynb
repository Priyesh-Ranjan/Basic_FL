{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run multple exp and save model as pca's vector for clustering\n",
    "\n",
    "to run jobs in parallel:\n",
    "\n",
    "``` parallel --progress --tmux --jobs 2 --delay 10 <batchjobs.sh```\n",
    "\n",
    "to switch betwenn tmux: `ctrl+b`+`n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for imdb\n",
    "GARs=[\"fedavg\",\"median\",\"gm\",\"mkrum\",\"foolsGold\",\"residualbase\"]\n",
    "filename=\"batchjobs_imdb.sh\"\n",
    "print(\"\",file=open(filename,\"w\"))\n",
    "attack = [\\\n",
    "          \"n_attacker_labelFlipping\",\n",
    "          \"n_attacker_omniscient\"\n",
    "         ]\n",
    "n_attackers=[\\\n",
    "             1,2,3,4,]\n",
    "dataset='imdb'\n",
    "loader_type='dirichlet'\n",
    "epochs=10\n",
    "outfolder='compareAllAttacks'\n",
    "save_model_weights=True\n",
    "    \n",
    "# repeat=0\n",
    "for gar in GARs:\n",
    "    for repeat in [1]:\n",
    "        name=f\"No_Attack({repeat})\"\n",
    "        out = f\"python main.py --GAR {gar:<15} --optimizer Adam --attacks \\\"{name}\\\" \\\n",
    "        --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "        --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "        --dataset {dataset} --epochs {epochs} \"\n",
    "        if save_model_weights:\n",
    "            out+=\"--save_model_weights\"\n",
    "#         out+=f\" |& tee \\\"results/exp_out_log/{dataset}_{loader_type}_{name}_{gar}.txt\\\"\"\n",
    "        print(out,file=open(filename,\"a\"))\n",
    "\n",
    "\n",
    "    for i in attack:\n",
    "        for j in n_attackers:\n",
    "            for repeat in [1]:\n",
    "                name=i.split(\"_\")[-1]+\"_\"+str(j)+f\"({repeat})\"\n",
    "                out = f\"python main.py --GAR {gar:<15} --optimizer Adam --attacks \\\"{name}\\\" \\\n",
    "            --{i} {j} --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "            --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "            --dataset {dataset} --epochs {epochs} \"\n",
    "                if save_model_weights:\n",
    "                    out+=\"--save_model_weights\"\n",
    "#                 out+=f\" |& tee \\\"results/exp_out_log/{dataset}_{loader_type}_{name}_{gar}.txt\\\"\"\n",
    "\n",
    "                print(out,file=open(filename,\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for imdb\n",
    "GARs=[\"foolsGold\"]\n",
    "filename=\"batchjobs_imdb_foolsgold.sh\"\n",
    "print(\"\",file=open(filename,\"w\"))\n",
    "attack = [\\\n",
    "          \"n_attacker_labelFlipping\",\n",
    "          \"n_attacker_omniscient\"\n",
    "         ]\n",
    "n_attackers=[\\\n",
    "             1,2,3,4,]\n",
    "dataset='imdb'\n",
    "loader_type='dirichlet'\n",
    "epochs=10\n",
    "outfolder='compareAllAttacks'\n",
    "save_model_weights=False\n",
    "    \n",
    "# repeat=0\n",
    "for gar in GARs:\n",
    "    for repeat in [1]:\n",
    "        name=f\"No_Attack({repeat})\"\n",
    "        out = f\"python main.py --GAR {gar:<15} --optimizer Adam --attacks \\\"{name}\\\" \\\n",
    "        --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "        --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "        --dataset {dataset} --epochs {epochs} \"\n",
    "        if save_model_weights:\n",
    "            out+=\"--save_model_weights\"\n",
    "#         out+=f\" |& tee \\\"results/exp_out_log/{dataset}_{loader_type}_{name}_{gar}.txt\\\"\"\n",
    "        print(out,file=open(filename,\"a\"))\n",
    "\n",
    "\n",
    "    for i in attack:\n",
    "        for j in n_attackers:\n",
    "            for repeat in [1]:\n",
    "                name=i.split(\"_\")[-1]+\"_\"+str(j)+f\"({repeat})\"\n",
    "                out = f\"python main.py --GAR {gar:<15} --optimizer Adam --attacks \\\"{name}\\\" \\\n",
    "            --{i} {j} --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "            --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "            --dataset {dataset} --epochs {epochs} \"\n",
    "                if save_model_weights:\n",
    "                    out+=\"--save_model_weights\"\n",
    "#                 out+=f\" |& tee \\\"results/exp_out_log/{dataset}_{loader_type}_{name}_{gar}.txt\\\"\"\n",
    "\n",
    "                print(out,file=open(filename,\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for semantic backdoor\n",
    "GARs=[\"fedavg\",\"median\",\"gm\",\"mkrum\"]\n",
    "filename=\"batchjobs_all_attacks3.sh\"\n",
    "print(\"\",file=open(filename,\"w\"))\n",
    "attack = [\\\n",
    "          \"n_attacker_semanticBackdoor\",\n",
    "          \"n_attacker_backdoor\", \n",
    "          \"n_attacker_labelFlippingDirectional\",\n",
    "          \"n_attacker_omniscient\"\n",
    "         ]\n",
    "n_attackers=[\\\n",
    "             1,2,3,4,]\n",
    "dataset='cifar100'\n",
    "loader_type='dirichlet'\n",
    "epochs=30\n",
    "outfolder='compareAllAttacks'\n",
    "save_model_weights=True\n",
    "    \n",
    "# repeat=0\n",
    "for gar in GARs:\n",
    "    for repeat in [0,1,2]:\n",
    "        name=f\"No_Attack({repeat})\"\n",
    "        out = f\"python main.py --GAR {gar:<15} --attacks \\\"{name}\\\" \\\n",
    "        --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "        --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "        --dataset {dataset} --epochs {epochs} \"\n",
    "        if save_model_weights:\n",
    "            out+=\"--save_model_weights\"\n",
    "        print(out,file=open(filename,\"a\"))\n",
    "\n",
    "\n",
    "    for i in attack:\n",
    "        for j in n_attackers:\n",
    "            for repeat in [0,1,2]:\n",
    "                name=i.split(\"_\")[-1]+\"_\"+str(j)+f\"({repeat})\"\n",
    "                out = f\"python main.py --GAR {gar:<15} --attacks \\\"{name}\\\" \\\n",
    "            --{i} {j} --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "            --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "            --dataset {dataset} --epochs {epochs} \"\n",
    "                if save_model_weights:\n",
    "                    out+=\"--save_model_weights\"\n",
    "\n",
    "                print(out,file=open(filename,\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for semantic backdoor\n",
    "GARs=[\"foolsgold\"]\n",
    "filename=\"batchjobs_cifar_foolsgold.sh\"\n",
    "print(\"\",file=open(filename,\"w\"))\n",
    "attack = [\\\n",
    "          \"n_attacker_semanticBackdoor\",\n",
    "          \"n_attacker_backdoor\", \n",
    "          \"n_attacker_labelFlippingDirectional\",\n",
    "          \"n_attacker_omniscient\"\n",
    "         ]\n",
    "n_attackers=[\\\n",
    "             1,2,3,4,]\n",
    "dataset='cifar'\n",
    "loader_type='dirichlet'\n",
    "epochs=30\n",
    "outfolder='compareAllAttacks'\n",
    "save_model_weights=True\n",
    "    \n",
    "# repeat=0\n",
    "for gar in GARs:\n",
    "    for repeat in [0]:\n",
    "        name=f\"No_Attack({repeat})\"\n",
    "        out = f\"python main.py --GAR {gar:<15} --attacks \\\"{name}\\\" \\\n",
    "        --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "        --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "        --dataset {dataset} --epochs {epochs} \"\n",
    "        if save_model_weights:\n",
    "            out+=\"--save_model_weights\"\n",
    "        print(out,file=open(filename,\"a\"))\n",
    "\n",
    "\n",
    "    for i in attack:\n",
    "        for j in n_attackers:\n",
    "            for repeat in [0]:\n",
    "                name=i.split(\"_\")[-1]+\"_\"+str(j)+f\"({repeat})\"\n",
    "                out = f\"python main.py --GAR {gar:<15} --attacks \\\"{name}\\\" \\\n",
    "            --{i} {j} --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "            --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "            --dataset {dataset} --epochs {epochs} \"\n",
    "                if save_model_weights:\n",
    "                    out+=\"--save_model_weights\"\n",
    "\n",
    "                print(out,file=open(filename,\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for semantic backdoor\n",
    "GARs=[\"attention\"]\n",
    "filename=\"batchjobs_cifar_attention.sh\"\n",
    "print(\"\",file=open(filename,\"w\"))\n",
    "attack = [\\\n",
    "#           \"n_attacker_semanticBackdoor\",\n",
    "          \"n_attacker_backdoor\", \n",
    "#           \"n_attacker_labelFlippingDirectional\",\n",
    "#           \"n_attacker_omniscient\"\n",
    "         ]\n",
    "n_attackers=[\\\n",
    "             1,2,3,4,]\n",
    "dataset='cifar'\n",
    "loader_type='dirichlet'\n",
    "epochs=30\n",
    "outfolder='compareAllAttacks'\n",
    "save_model_weights=True\n",
    "\n",
    "path_to_aggNet=\"./aggregator/attention_cifar_backdoor.pt\"\n",
    "\n",
    "for gar in GARs:\n",
    "    for i in attack:\n",
    "        for j in n_attackers:\n",
    "            for repeat in [0]:\n",
    "                name=i.split(\"_\")[-1]+\"_\"+str(j)+f\"({repeat})\"\n",
    "                out = f\"python main.py --GAR {gar:<15} --attacks \\\"{name}\\\" \\\n",
    "            --{i} {j} --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "            --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "            --dataset {dataset} --epochs {epochs} --path_to_aggNet \\\"{path_to_aggNet}\\\" \"\n",
    "                if save_model_weights:\n",
    "                    out+=\"--save_model_weights\"\n",
    "\n",
    "                print(out,file=open(filename,\"a\"))\n",
    "                \n",
    "path_to_aggNet=\"./aggregator/attention_cifar_modelPoisoning.pt\"\n",
    "attack = [\\\n",
    "#           \"n_attacker_semanticBackdoor\",\n",
    "#           \"n_attacker_backdoor\", \n",
    "#           \"n_attacker_labelFlippingDirectional\",\n",
    "          \"n_attacker_omniscient\"\n",
    "         ]\n",
    "for gar in GARs:\n",
    "    for i in attack:\n",
    "        for j in n_attackers:\n",
    "            for repeat in [0]:\n",
    "                name=i.split(\"_\")[-1]+\"_\"+str(j)+f\"({repeat})\"\n",
    "                out = f\"python main.py --GAR {gar:<15} --attacks \\\"{name}\\\" \\\n",
    "            --{i} {j} --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "            --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "            --dataset {dataset} --epochs {epochs} --path_to_aggNet \\\"{path_to_aggNet}\\\" \"\n",
    "                if save_model_weights:\n",
    "                    out+=\"--save_model_weights\"\n",
    "\n",
    "                print(out,file=open(filename,\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for semantic backdoor\n",
    "GARs=[\"mkrum\"]\n",
    "filename=\"batchjobs_missedExp1.sh\"\n",
    "print(\"\",file=open(filename,\"w\"))\n",
    "attack = [\\\n",
    "          \"n_attacker_semanticBackdoor\",\n",
    "          \"n_attacker_backdoor\", \n",
    "#           \"n_attacker_labelFlippingDirectional\",\n",
    "          \"n_attacker_omniscient\"\n",
    "         ]\n",
    "n_attackers=[\\\n",
    "             1,2,3,4,]\n",
    "dataset='cifar'\n",
    "loader_type='dirichlet'\n",
    "epochs=30\n",
    "outfolder='compareAllAttacks'\n",
    "save_model_weights=False\n",
    "    \n",
    "# repeat=0\n",
    "for gar in GARs:\n",
    "    for i in attack:\n",
    "        for j in n_attackers:\n",
    "            for repeat in [1]:\n",
    "                name=i.split(\"_\")[-1]+\"_\"+str(j)+f\"({repeat})\"\n",
    "                out = f\"python main.py --GAR {gar:<15} --attacks \\\"{name}\\\" \\\n",
    "            --{i} {j} --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "            --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "            --dataset {dataset} --epochs {epochs} \"\n",
    "                if save_model_weights:\n",
    "                    out+=\"--save_model_weights\"\n",
    "\n",
    "                print(out,file=open(filename,\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for semantic backdoor\n",
    "GARs=[\"residualbase\"]\n",
    "filename=\"batchjobs_all_attacks8.sh\"\n",
    "print(\"\",file=open(filename,\"w\"))\n",
    "attack = [\\\n",
    "          \"n_attacker_semanticBackdoor\",\n",
    "          \"n_attacker_backdoor\", \n",
    "          \"n_attacker_labelFlippingDirectional\",\n",
    "          \"n_attacker_omniscient\"\n",
    "         ]\n",
    "n_attackers=[\\\n",
    "             1,2,3,4,]\n",
    "dataset='cifar'\n",
    "loader_type='dirichlet'\n",
    "epochs=30\n",
    "outfolder='compareAllAttacks'\n",
    "save_model_weights=False\n",
    "    \n",
    "# repeat=0\n",
    "for gar in GARs:\n",
    "    for repeat in [0]:\n",
    "        name=f\"No_Attack({repeat})\"\n",
    "        out = f\"python main.py --GAR {gar:<15} --attacks \\\"{name}\\\" \\\n",
    "        --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "        --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "        --dataset {dataset} --epochs {epochs} \"\n",
    "        if save_model_weights:\n",
    "            out+=\"--save_model_weights\"\n",
    "        print(out,file=open(filename,\"a\"))\n",
    "\n",
    "\n",
    "    for i in attack:\n",
    "        for j in n_attackers:\n",
    "            for repeat in [0]:\n",
    "                name=i.split(\"_\")[-1]+\"_\"+str(j)+f\"({repeat})\"\n",
    "                out = f\"python main.py --GAR {gar:<15} --attacks \\\"{name}\\\" \\\n",
    "            --{i} {j} --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "            --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "            --dataset {dataset} --epochs {epochs} \"\n",
    "                if save_model_weights:\n",
    "                    out+=\"--save_model_weights\"\n",
    "\n",
    "                print(out,file=open(filename,\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for semantic backdoor\n",
    "GARs=[\"foolsgold\"]\n",
    "filename=\"batchjobs_all_attacks6.sh\"\n",
    "print(\"\",file=open(filename,\"w\"))\n",
    "attack = [\\\n",
    "#           \"n_attacker_semanticBackdoor\",\n",
    "          \"n_attacker_backdoor\", \n",
    "          \"n_attacker_labelFlippingDirectional\",\n",
    "          \"n_attacker_omniscient\"\n",
    "         ]\n",
    "n_attackers=[\\\n",
    "             1,2,3,4,]\n",
    "dataset='mnist'\n",
    "loader_type='dirichlet'\n",
    "epochs=30\n",
    "outfolder='compareAllAttacks'\n",
    "save_model_weights=True\n",
    "    \n",
    "# repeat=0\n",
    "for gar in GARs:\n",
    "    for repeat in [0]:\n",
    "        name=f\"No_Attack({repeat})\"\n",
    "        out = f\"python main.py --GAR {gar:<15} --attacks \\\"{name}\\\" \\\n",
    "        --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "        --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "        --dataset {dataset} --epochs {epochs} \"\n",
    "        if save_model_weights:\n",
    "            out+=\"--save_model_weights\"\n",
    "        print(out,file=open(filename,\"a\"))\n",
    "\n",
    "\n",
    "    for i in attack:\n",
    "        for j in n_attackers:\n",
    "            for repeat in [0]:\n",
    "                name=i.split(\"_\")[-1]+\"_\"+str(j)+f\"({repeat})\"\n",
    "                out = f\"python main.py --GAR {gar:<15} --attacks \\\"{name}\\\" \\\n",
    "            --{i} {j} --loader_type {loader_type} --output_folder {outfolder} \\\n",
    "            --experiment_name \\\"{dataset}_{loader_type}/{name}/{gar}\\\" \\\n",
    "            --dataset {dataset} --epochs {epochs} \"\n",
    "                if save_model_weights:\n",
    "                    out+=\"--save_model_weights\"\n",
    "\n",
    "                print(out,file=open(filename,\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\",file=open(\"ablation.sh\",\"w\"))\n",
    "for eps in [0.0001, 0.001,0.002,0.005,0.01, 0.05]:\n",
    "    for c in [0.5,1,10, 20, 100]:\n",
    "        print(f\"python aggregator/train_attention.py @aggregator/args --eps {eps} --scale {c} --epochs 100\",file=open(\"ablation.sh\",\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\",file=open(\"ablation_cifar.sh\",\"w\"))\n",
    "for eps in [0.0001, 0.001,0.002,0.005,0.01, 0.05]:\n",
    "    for c in [0.5,1,10, 20, 100]:\n",
    "        print(f\"python aggregator/train_attention.py @aggregator/args_cifar --eps {eps} --scale {c}\",file=open(\"ablation_cifar.sh\",\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py --GAR fedavg          --attacks \"No_Attack(0)\"         --loader_type dirichlet --output_folder debug         --experiment_name \"debug\"         --dataset cifar100 --epochs 30 --save_model_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python aggregator/train_attention.py @aggregator/args_cifar_backdoor --eps 0.05 --scale 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python aggregator/train_attention.py @aggregator/args_cifar_backdoor_noC --eps 0.05 --scale 1 \n",
    "python aggregator/train_attention.py @aggregator/args_cifar_backdoor_noEps --eps 0 --scale 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python aggregator/train_attention.py @aggregator/args_imdb --eps 0.05 --scale 10 --max_round 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python aggregator/train_MLP.py @aggregator/args_cifar_backdoor_MLP "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
